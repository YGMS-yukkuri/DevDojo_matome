線形、非線形分析を自分なりに調べてわかりやすく言語化する

Google Colabとか使って実際に実行するのも良き
AIによる出力を使ってもいいが、内容の良さを重きにおいてみてるよ☆

## 線形回帰とは
変数aとbがあったとき、その数値の重要度を示す*wa*と*wb*をaとbにそれぞれ掛け合わせた値を求め、足し合わせることで結果を求める、という手法をとっている。

__例__ 家の値段を予想させるとき、築年数による値段をa,切片をnとすると、出力となるyは、``` y = 0.4a + n ``` と表すことができる。このとき、0.4という値はaがどのくらいyに関係し、重要かどうかを示す。
上に示したように、線形回帰を用いた場合、一次関数の直線のグラフに行き着く。
#### 学習方式
- 最小二乗法
    - 誤差の二乗が最小になる直線を計算し、それを用いるというという学習方式。
    - 小規模なデータに向いている
- 勾配降下法
    - 誤差が小さくなる方向へ少しずつパラメータを更新するという学習方式。
    - 大規模なデータに向いている
### 線形回帰のメリットとデメリット
#### メリット
- 予想される結果が求まる仕組みがわかりやすい
- 非線形よりも計算が早い
- 深層学習の基本のため、理解することが第一歩となる
#### デメリット
- 外れ値に弱く、学習されてしまうと予想精度が大きく下がる。
- 距離や大きさなど、数字に起こせるものに対しては有用だが画像や音声などの複雑なデータの処理には不向き
- 入力される変数と結果の関係が直線的になるものしか表現することができない

