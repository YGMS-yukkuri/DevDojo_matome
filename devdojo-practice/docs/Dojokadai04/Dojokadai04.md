線形、非線形分析を自分なりに調べてわかりやすく言語化する

Google Colabとか使って実際に実行するのも良き
AIによる出力を使ってもいいが、内容の良さを重きにおいてみてるよ☆

## 線形回帰とは
変数の数字などに対し、解釈や分類に応じて倍率をつけ、足し合わせて結果を予測するという方法。
具体的には、変数aとbがあったとき、その数値の重要度を示す*wa*と*wb*をaとbにそれぞれ掛け合わせた値を求め、足し合わせることで結果を求める、という手法をとる。

また、深層学習をする際の基本形。

__例__ 家の値段を予想させるとき、築年数による値段をa,切片をnとすると、出力となるyは、``` y = 0.4a + n ``` と表すことができる。このとき、0.4という値はaがどのくらいyに関係し、重要かどうかを示す。
上に示したように、線形回帰を用いた場合、一次関数の直線のグラフに行き着く。
### 学習方式
- 最小二乗法
    - 誤差の二乗が最小になる直線を計算し、それを用いるというという学習方式。
    - 小規模なデータに向いている
- 勾配降下法
    - 誤差が小さくなる方向へ少しずつパラメータを更新するという学習方式。
    - 大規模なデータに向いている
### 線形回帰のメリットとデメリット
#### メリット
- 予想される結果が求まる仕組みがわかりやすい
- 非線形よりも計算が早い
- 誤差が最小となる点が存在するため、理論的な最適解を求めることができる
- 比較的少ないデータでも学習させられる
#### デメリット
- 外れ値に弱く、学習されてしまうと予想精度が大きく下がる。
- 距離や大きさなど、数字に起こせるものに対しては有用だが画像や音声などの複雑なデータの処理には不向き
- 入力される変数と結果の関係が直線的になるものしか表現することができない

### 線形回帰が適す場面
#### データが比例する場合や、aが1増えたときにbはどのくらい変わるか、を表現するときに使用する
- 自動車の走行距離に対する燃料消費量
- 年収と幸福度
#### 高速で確実な結果が欲しいとき
- 組み込みのシステムなどで、素早く計算することが求められる時に採用する
#### 学習させるデータが少ないとき
- 学習データが数百程度の場合、非線形回帰で行うとほぼ確実に過学習の現象が発生するため。
### 線形回帰が適さない場面
- そもそも関係が線形でない場合
    - 音声や画像など、複雑な要素が絡むデータは適さない


## 非線形回帰とは
変数に対して様々な分類をつけたり、変数の変わり方についての解釈の幅がとても広いという特徴がある。また、グラフに起こしたときは変数の数次元の空間となり、曲線や曲面を用いたグラフとなる。
### 学習方式
線形回帰とは違い、誤差の大きさを表すグラフの最も小さくなる点を数学的に求めることが難しいため、大量のデータで繰り返し最適な値に近づけていく反復最適化の方法をとる。
- 勾配降下法
    - 線形回帰と同様、誤差が小さくなるほうへパラメータを少しづつ調節していく。
- 誤差逆伝播法（ニューラルネット）
    - 出力された予想に対し、起こった誤差を勾配降下法でニューラルネットワークの一つ一つにパラメーターを再分配していく。

*線形回帰の際に使用できた最小二乗法は使用できない*
### 非線形回帰のメリットとデメリット
#### メリット
- 線形回帰とは異なり、関係が直線的でなくてもOK
- データから関係を学んでいく方式のため、柔軟。
- 音声や画像など、現実にある直線では表せない複雑なものを分類・学習することができる
- 線形回帰よりも複雑な分類が得意で精度も高い
- グラフが三次元なため、折れ曲がりや閾値など、すべてを表現することができる。
#### デメリット
- 結果を予想する段階の計算が複雑になりブラックボックス化する。
- データの本質となる部分だけでなく、たまたま共通した関係のない部分に共通性を見出し、間違った結果を導くということが起こりやすい。
    - サンプルとなるデータが少ないほど不正確になりやすい
- 最適とする解を確実なものにすることができない。
    - 誤差を表現するグラフの底が一点とは限らないため、初期値として設定する部分によって結果が変わる。
- 学習方式が反復最適化方式なため、膨大な計算が必要となる。

### 非線形回帰が適する場面
#### そもそもの現象が線形で表せないとき
- 化学反応や、温度と反応速度
- 経済の景気変動
など
#### 予測精度が最重要なとき
- 求める過程は多少あいまいになっても、予測される結果の精度が当たれば良い、という場面
    - 需要予測
    - 音声や画像認識
    など
#### 学習対象データが大量にあるとき
- データが多いほど非線形回帰は力を発揮するため。
### 非線形回帰が適さない場面
- データが少ない場合
- すでに数学的に証明された式がある場合
- 計算させるコンピュータのパワーや時間がない場合